{"cells":[{"cell_type":"code","execution_count":null,"id":"9dad0abc-34ef-44db-9a88-32d9d8ab2fbe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2758,"status":"ok","timestamp":1728552253412,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"9dad0abc-34ef-44db-9a88-32d9d8ab2fbe","outputId":"0430ea3f-e63f-4af0-bf72-09f2f6616643"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.0.1)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n","Requirement already satisfied: gradio-client==1.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.0)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.9)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (2024.6.1)\n","Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (12.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}],"source":["#Write any package/module installation that you need here\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms, models\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","!pip install gradio\n","import gradio as gr\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"id":"dS-hLhgppQ1Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5654,"status":"ok","timestamp":1728552259062,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"dS-hLhgppQ1Y","outputId":"35bc1d40-1f22-4273-e37c-5d1adabf0503"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"eOU90goy3hTV","metadata":{"id":"eOU90goy3hTV"},"outputs":[],"source":["# Data Augmentation and Transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),        # Augmentation: Random horizontal flip\n","    transforms.RandomRotation(10),            # Augmentation: Random rotation\n","    transforms.ToTensor(),                    # Convert images to tensor\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize as per ImageNet stats\n","])\n","\n","# Load dataset from Google Drive\n","dataset_dir = '/content/drive/MyDrive/AI Engineer Bootcamp/data/chest_xray'\n","flower_dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n","\n","# Split dataset into training and testing sets\n","train_dataset = '/content/drive/MyDrive/AI Engineer Bootcamp/data/chest_xray/train'\n","test_dataset = '/content/drive/MyDrive/AI Engineer Bootcamp/data/chest_xray/test'\n","\n","train_dataset = datasets.ImageFolder(root=train_dataset, transform=transform)\n","test_dataset = datasets.ImageFolder(root=test_dataset, transform=transform)\n","# Dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"fa2ec9d0-da97-499a-91ce-d689321207cd","metadata":{"id":"fa2ec9d0-da97-499a-91ce-d689321207cd"},"outputs":[],"source":["#Write your code to build your model here\n","\n","accuracy = 0\n","model = models.resnet18(pretrained=True)\n","\n","\n","model.fc = nn.Linear(model.fc.in_features, 2)\n","\n","# Send model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define Loss Function and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Learning Rate Scheduler\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","# Define accuracy calculation function\n","def calculate_accuracy(outputs, labels):\n","    _, predicted = torch.max(outputs, 1)\n","    correct = (predicted == labels).sum().item()\n","    total = labels.size(0)\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# Training Function\n","def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=10):\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        model.train()\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            accuracy = calculate_accuracy(outputs, labels)\n","            correct += (outputs.argmax(1) == labels).sum().item()\n","            total += labels.size(0)\n","\n","\n","            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n","\n","\n","        # Step the scheduler\n","        scheduler.step()\n","\n","    print(\"Finished Training\")\n","\n","# Evaluation Function\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","\n","            correct += (outputs.argmax(1) == labels).sum().item()\n","            total += labels.size(0)\n","\n","    accuracy = 100 * correct / total\n","    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n","    return accuracy\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"cded4e17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1560009,"status":"ok","timestamp":1728553821843,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"cded4e17","outputId":"e637c73f-0bd5-44c4-a4e9-6238089b7368"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Step [1/163], Loss: 0.0112, Accuracy: 31.25%\n","Epoch [1/5], Step [2/163], Loss: 0.0155, Accuracy: 57.81%\n","Epoch [1/5], Step [3/163], Loss: 0.0189, Accuracy: 65.62%\n","Epoch [1/5], Step [4/163], Loss: 0.0194, Accuracy: 73.44%\n","Epoch [1/5], Step [5/163], Loss: 0.0257, Accuracy: 76.88%\n","Epoch [1/5], Step [6/163], Loss: 0.0342, Accuracy: 78.65%\n","Epoch [1/5], Step [7/163], Loss: 0.0385, Accuracy: 79.02%\n","Epoch [1/5], Step [8/163], Loss: 0.0409, Accuracy: 80.47%\n","Epoch [1/5], Step [9/163], Loss: 0.0462, Accuracy: 81.25%\n","Epoch [1/5], Step [10/163], Loss: 0.0504, Accuracy: 81.56%\n","Epoch [1/5], Step [11/163], Loss: 0.0514, Accuracy: 82.67%\n","Epoch [1/5], Step [12/163], Loss: 0.0533, Accuracy: 83.07%\n","Epoch [1/5], Step [13/163], Loss: 0.0562, Accuracy: 83.17%\n","Epoch [1/5], Step [14/163], Loss: 0.0568, Accuracy: 84.15%\n","Epoch [1/5], Step [15/163], Loss: 0.0584, Accuracy: 84.58%\n","Epoch [1/5], Step [16/163], Loss: 0.0615, Accuracy: 84.38%\n","Epoch [1/5], Step [17/163], Loss: 0.0617, Accuracy: 85.29%\n","Epoch [1/5], Step [18/163], Loss: 0.0632, Accuracy: 85.59%\n","Epoch [1/5], Step [19/163], Loss: 0.0659, Accuracy: 85.86%\n","Epoch [1/5], Step [20/163], Loss: 0.0698, Accuracy: 86.09%\n","Epoch [1/5], Step [21/163], Loss: 0.0705, Accuracy: 86.76%\n","Epoch [1/5], Step [22/163], Loss: 0.0726, Accuracy: 87.07%\n","Epoch [1/5], Step [23/163], Loss: 0.0753, Accuracy: 87.36%\n","Epoch [1/5], Step [24/163], Loss: 0.0771, Accuracy: 87.50%\n","Epoch [1/5], Step [25/163], Loss: 0.0793, Accuracy: 87.62%\n","Epoch [1/5], Step [26/163], Loss: 0.0806, Accuracy: 87.62%\n","Epoch [1/5], Step [27/163], Loss: 0.0828, Accuracy: 87.73%\n","Epoch [1/5], Step [28/163], Loss: 0.0844, Accuracy: 87.83%\n","Epoch [1/5], Step [29/163], Loss: 0.0856, Accuracy: 88.15%\n","Epoch [1/5], Step [30/163], Loss: 0.0874, Accuracy: 88.33%\n","Epoch [1/5], Step [31/163], Loss: 0.0878, Accuracy: 88.61%\n","Epoch [1/5], Step [32/163], Loss: 0.0898, Accuracy: 88.77%\n","Epoch [1/5], Step [33/163], Loss: 0.0917, Accuracy: 88.83%\n","Epoch [1/5], Step [34/163], Loss: 0.0920, Accuracy: 89.15%\n","Epoch [1/5], Step [35/163], Loss: 0.0937, Accuracy: 89.29%\n","Epoch [1/5], Step [36/163], Loss: 0.0946, Accuracy: 89.50%\n","Epoch [1/5], Step [37/163], Loss: 0.0963, Accuracy: 89.61%\n","Epoch [1/5], Step [38/163], Loss: 0.0975, Accuracy: 89.72%\n","Epoch [1/5], Step [39/163], Loss: 0.1000, Accuracy: 89.90%\n","Epoch [1/5], Step [40/163], Loss: 0.1028, Accuracy: 89.92%\n","Epoch [1/5], Step [41/163], Loss: 0.1041, Accuracy: 90.02%\n","Epoch [1/5], Step [42/163], Loss: 0.1061, Accuracy: 90.03%\n","Epoch [1/5], Step [43/163], Loss: 0.1067, Accuracy: 90.19%\n","Epoch [1/5], Step [44/163], Loss: 0.1080, Accuracy: 90.27%\n","Epoch [1/5], Step [45/163], Loss: 0.1086, Accuracy: 90.42%\n","Epoch [1/5], Step [46/163], Loss: 0.1113, Accuracy: 90.42%\n","Epoch [1/5], Step [47/163], Loss: 0.1116, Accuracy: 90.56%\n","Epoch [1/5], Step [48/163], Loss: 0.1129, Accuracy: 90.62%\n","Epoch [1/5], Step [49/163], Loss: 0.1135, Accuracy: 90.75%\n","Epoch [1/5], Step [50/163], Loss: 0.1150, Accuracy: 90.81%\n","Epoch [1/5], Step [51/163], Loss: 0.1179, Accuracy: 90.69%\n","Epoch [1/5], Step [52/163], Loss: 0.1199, Accuracy: 90.75%\n","Epoch [1/5], Step [53/163], Loss: 0.1204, Accuracy: 90.92%\n","Epoch [1/5], Step [54/163], Loss: 0.1210, Accuracy: 91.09%\n","Epoch [1/5], Step [55/163], Loss: 0.1245, Accuracy: 91.02%\n","Epoch [1/5], Step [56/163], Loss: 0.1270, Accuracy: 91.02%\n","Epoch [1/5], Step [57/163], Loss: 0.1274, Accuracy: 91.12%\n","Epoch [1/5], Step [58/163], Loss: 0.1276, Accuracy: 91.27%\n","Epoch [1/5], Step [59/163], Loss: 0.1291, Accuracy: 91.37%\n","Epoch [1/5], Step [60/163], Loss: 0.1301, Accuracy: 91.35%\n","Epoch [1/5], Step [61/163], Loss: 0.1305, Accuracy: 91.50%\n","Epoch [1/5], Step [62/163], Loss: 0.1318, Accuracy: 91.53%\n","Epoch [1/5], Step [63/163], Loss: 0.1331, Accuracy: 91.62%\n","Epoch [1/5], Step [64/163], Loss: 0.1334, Accuracy: 91.75%\n","Epoch [1/5], Step [65/163], Loss: 0.1336, Accuracy: 91.88%\n","Epoch [1/5], Step [66/163], Loss: 0.1345, Accuracy: 91.95%\n","Epoch [1/5], Step [67/163], Loss: 0.1353, Accuracy: 92.02%\n","Epoch [1/5], Step [68/163], Loss: 0.1357, Accuracy: 92.14%\n","Epoch [1/5], Step [69/163], Loss: 0.1364, Accuracy: 92.21%\n","Epoch [1/5], Step [70/163], Loss: 0.1399, Accuracy: 92.23%\n","Epoch [1/5], Step [71/163], Loss: 0.1425, Accuracy: 92.30%\n","Epoch [1/5], Step [72/163], Loss: 0.1430, Accuracy: 92.40%\n","Epoch [1/5], Step [73/163], Loss: 0.1441, Accuracy: 92.42%\n","Epoch [1/5], Step [74/163], Loss: 0.1463, Accuracy: 92.40%\n","Epoch [1/5], Step [75/163], Loss: 0.1491, Accuracy: 92.38%\n","Epoch [1/5], Step [76/163], Loss: 0.1500, Accuracy: 92.39%\n","Epoch [1/5], Step [77/163], Loss: 0.1513, Accuracy: 92.41%\n","Epoch [1/5], Step [78/163], Loss: 0.1526, Accuracy: 92.47%\n","Epoch [1/5], Step [79/163], Loss: 0.1538, Accuracy: 92.48%\n","Epoch [1/5], Step [80/163], Loss: 0.1545, Accuracy: 92.54%\n","Epoch [1/5], Step [81/163], Loss: 0.1555, Accuracy: 92.63%\n","Epoch [1/5], Step [82/163], Loss: 0.1566, Accuracy: 92.68%\n","Epoch [1/5], Step [83/163], Loss: 0.1576, Accuracy: 92.73%\n","Epoch [1/5], Step [84/163], Loss: 0.1586, Accuracy: 92.78%\n","Epoch [1/5], Step [85/163], Loss: 0.1588, Accuracy: 92.87%\n","Epoch [1/5], Step [86/163], Loss: 0.1594, Accuracy: 92.95%\n","Epoch [1/5], Step [87/163], Loss: 0.1597, Accuracy: 93.03%\n","Epoch [1/5], Step [88/163], Loss: 0.1621, Accuracy: 92.97%\n","Epoch [1/5], Step [89/163], Loss: 0.1624, Accuracy: 93.05%\n","Epoch [1/5], Step [90/163], Loss: 0.1640, Accuracy: 93.06%\n","Epoch [1/5], Step [91/163], Loss: 0.1644, Accuracy: 93.10%\n","Epoch [1/5], Step [92/163], Loss: 0.1646, Accuracy: 93.17%\n","Epoch [1/5], Step [93/163], Loss: 0.1652, Accuracy: 93.21%\n","Epoch [1/5], Step [94/163], Loss: 0.1669, Accuracy: 93.18%\n","Epoch [1/5], Step [95/163], Loss: 0.1689, Accuracy: 93.16%\n","Epoch [1/5], Step [96/163], Loss: 0.1692, Accuracy: 93.23%\n","Epoch [1/5], Step [97/163], Loss: 0.1698, Accuracy: 93.30%\n","Epoch [1/5], Step [98/163], Loss: 0.1705, Accuracy: 93.34%\n","Epoch [1/5], Step [99/163], Loss: 0.1715, Accuracy: 93.37%\n","Epoch [1/5], Step [100/163], Loss: 0.1724, Accuracy: 93.41%\n","Epoch [1/5], Step [101/163], Loss: 0.1725, Accuracy: 93.47%\n","Epoch [1/5], Step [102/163], Loss: 0.1747, Accuracy: 93.47%\n","Epoch [1/5], Step [103/163], Loss: 0.1758, Accuracy: 93.45%\n","Epoch [1/5], Step [104/163], Loss: 0.1769, Accuracy: 93.45%\n","Epoch [1/5], Step [105/163], Loss: 0.1774, Accuracy: 93.48%\n","Epoch [1/5], Step [106/163], Loss: 0.1780, Accuracy: 93.51%\n","Epoch [1/5], Step [107/163], Loss: 0.1786, Accuracy: 93.55%\n","Epoch [1/5], Step [108/163], Loss: 0.1817, Accuracy: 93.49%\n","Epoch [1/5], Step [109/163], Loss: 0.1826, Accuracy: 93.52%\n","Epoch [1/5], Step [110/163], Loss: 0.1846, Accuracy: 93.49%\n","Epoch [1/5], Step [111/163], Loss: 0.1847, Accuracy: 93.55%\n","Epoch [1/5], Step [112/163], Loss: 0.1849, Accuracy: 93.61%\n","Epoch [1/5], Step [113/163], Loss: 0.1852, Accuracy: 93.67%\n","Epoch [1/5], Step [114/163], Loss: 0.1873, Accuracy: 93.64%\n","Epoch [1/5], Step [115/163], Loss: 0.1913, Accuracy: 93.61%\n","Epoch [1/5], Step [116/163], Loss: 0.1922, Accuracy: 93.64%\n","Epoch [1/5], Step [117/163], Loss: 0.1924, Accuracy: 93.70%\n","Epoch [1/5], Step [118/163], Loss: 0.1929, Accuracy: 93.72%\n","Epoch [1/5], Step [119/163], Loss: 0.1963, Accuracy: 93.67%\n","Epoch [1/5], Step [120/163], Loss: 0.2008, Accuracy: 93.65%\n","Epoch [1/5], Step [121/163], Loss: 0.2016, Accuracy: 93.67%\n","Epoch [1/5], Step [122/163], Loss: 0.2022, Accuracy: 93.70%\n","Epoch [1/5], Step [123/163], Loss: 0.2032, Accuracy: 93.72%\n","Epoch [1/5], Step [124/163], Loss: 0.2035, Accuracy: 93.78%\n","Epoch [1/5], Step [125/163], Loss: 0.2037, Accuracy: 93.83%\n","Epoch [1/5], Step [126/163], Loss: 0.2045, Accuracy: 93.85%\n","Epoch [1/5], Step [127/163], Loss: 0.2051, Accuracy: 93.90%\n","Epoch [1/5], Step [128/163], Loss: 0.2063, Accuracy: 93.90%\n","Epoch [1/5], Step [129/163], Loss: 0.2067, Accuracy: 93.94%\n","Epoch [1/5], Step [130/163], Loss: 0.2073, Accuracy: 93.97%\n","Epoch [1/5], Step [131/163], Loss: 0.2093, Accuracy: 93.96%\n","Epoch [1/5], Step [132/163], Loss: 0.2130, Accuracy: 93.94%\n","Epoch [1/5], Step [133/163], Loss: 0.2142, Accuracy: 93.96%\n","Epoch [1/5], Step [134/163], Loss: 0.2147, Accuracy: 94.01%\n","Epoch [1/5], Step [135/163], Loss: 0.2155, Accuracy: 94.03%\n","Epoch [1/5], Step [136/163], Loss: 0.2158, Accuracy: 94.07%\n","Epoch [1/5], Step [137/163], Loss: 0.2161, Accuracy: 94.11%\n","Epoch [1/5], Step [138/163], Loss: 0.2168, Accuracy: 94.16%\n","Epoch [1/5], Step [139/163], Loss: 0.2178, Accuracy: 94.18%\n","Epoch [1/5], Step [140/163], Loss: 0.2191, Accuracy: 94.17%\n","Epoch [1/5], Step [141/163], Loss: 0.2195, Accuracy: 94.19%\n","Epoch [1/5], Step [142/163], Loss: 0.2207, Accuracy: 94.21%\n","Epoch [1/5], Step [143/163], Loss: 0.2229, Accuracy: 94.21%\n","Epoch [1/5], Step [144/163], Loss: 0.2240, Accuracy: 94.25%\n","Epoch [1/5], Step [145/163], Loss: 0.2243, Accuracy: 94.29%\n","Epoch [1/5], Step [146/163], Loss: 0.2246, Accuracy: 94.33%\n","Epoch [1/5], Step [147/163], Loss: 0.2248, Accuracy: 94.37%\n","Epoch [1/5], Step [148/163], Loss: 0.2263, Accuracy: 94.34%\n","Epoch [1/5], Step [149/163], Loss: 0.2269, Accuracy: 94.36%\n","Epoch [1/5], Step [150/163], Loss: 0.2272, Accuracy: 94.38%\n","Epoch [1/5], Step [151/163], Loss: 0.2283, Accuracy: 94.37%\n","Epoch [1/5], Step [152/163], Loss: 0.2299, Accuracy: 94.37%\n","Epoch [1/5], Step [153/163], Loss: 0.2302, Accuracy: 94.40%\n","Epoch [1/5], Step [154/163], Loss: 0.2309, Accuracy: 94.42%\n","Epoch [1/5], Step [155/163], Loss: 0.2312, Accuracy: 94.46%\n","Epoch [1/5], Step [156/163], Loss: 0.2321, Accuracy: 94.47%\n","Epoch [1/5], Step [157/163], Loss: 0.2340, Accuracy: 94.49%\n","Epoch [1/5], Step [158/163], Loss: 0.2342, Accuracy: 94.52%\n","Epoch [1/5], Step [159/163], Loss: 0.2347, Accuracy: 94.54%\n","Epoch [1/5], Step [160/163], Loss: 0.2361, Accuracy: 94.53%\n","Epoch [1/5], Step [161/163], Loss: 0.2367, Accuracy: 94.55%\n","Epoch [1/5], Step [162/163], Loss: 0.2377, Accuracy: 94.56%\n","Epoch [1/5], Step [163/163], Loss: 0.2386, Accuracy: 94.56%\n","Epoch [2/5], Step [1/163], Loss: 0.0001, Accuracy: 100.00%\n","Epoch [2/5], Step [2/163], Loss: 0.0014, Accuracy: 96.88%\n","Epoch [2/5], Step [3/163], Loss: 0.0037, Accuracy: 95.83%\n","Epoch [2/5], Step [4/163], Loss: 0.0040, Accuracy: 96.88%\n","Epoch [2/5], Step [5/163], Loss: 0.0073, Accuracy: 94.38%\n","Epoch [2/5], Step [6/163], Loss: 0.0074, Accuracy: 95.31%\n","Epoch [2/5], Step [7/163], Loss: 0.0087, Accuracy: 95.09%\n","Epoch [2/5], Step [8/163], Loss: 0.0114, Accuracy: 94.92%\n","Epoch [2/5], Step [9/163], Loss: 0.0124, Accuracy: 94.79%\n","Epoch [2/5], Step [10/163], Loss: 0.0136, Accuracy: 94.69%\n","Epoch [2/5], Step [11/163], Loss: 0.0142, Accuracy: 94.89%\n","Epoch [2/5], Step [12/163], Loss: 0.0147, Accuracy: 95.05%\n","Epoch [2/5], Step [13/163], Loss: 0.0154, Accuracy: 95.19%\n","Epoch [2/5], Step [14/163], Loss: 0.0156, Accuracy: 95.54%\n","Epoch [2/5], Step [15/163], Loss: 0.0157, Accuracy: 95.83%\n","Epoch [2/5], Step [16/163], Loss: 0.0162, Accuracy: 95.90%\n","Epoch [2/5], Step [17/163], Loss: 0.0169, Accuracy: 95.96%\n","Epoch [2/5], Step [18/163], Loss: 0.0173, Accuracy: 96.01%\n","Epoch [2/5], Step [19/163], Loss: 0.0175, Accuracy: 96.22%\n","Epoch [2/5], Step [20/163], Loss: 0.0193, Accuracy: 95.94%\n","Epoch [2/5], Step [21/163], Loss: 0.0211, Accuracy: 95.68%\n","Epoch [2/5], Step [22/163], Loss: 0.0213, Accuracy: 95.88%\n","Epoch [2/5], Step [23/163], Loss: 0.0215, Accuracy: 96.06%\n","Epoch [2/5], Step [24/163], Loss: 0.0246, Accuracy: 95.96%\n","Epoch [2/5], Step [25/163], Loss: 0.0247, Accuracy: 96.12%\n","Epoch [2/5], Step [26/163], Loss: 0.0250, Accuracy: 96.27%\n","Epoch [2/5], Step [27/163], Loss: 0.0266, Accuracy: 96.30%\n","Epoch [2/5], Step [28/163], Loss: 0.0272, Accuracy: 96.43%\n","Epoch [2/5], Step [29/163], Loss: 0.0291, Accuracy: 96.23%\n","Epoch [2/5], Step [30/163], Loss: 0.0296, Accuracy: 96.25%\n","Epoch [2/5], Step [31/163], Loss: 0.0309, Accuracy: 96.17%\n","Epoch [2/5], Step [32/163], Loss: 0.0318, Accuracy: 96.19%\n","Epoch [2/5], Step [33/163], Loss: 0.0320, Accuracy: 96.31%\n","Epoch [2/5], Step [34/163], Loss: 0.0323, Accuracy: 96.42%\n","Epoch [2/5], Step [35/163], Loss: 0.0332, Accuracy: 96.43%\n","Epoch [2/5], Step [36/163], Loss: 0.0338, Accuracy: 96.44%\n","Epoch [2/5], Step [37/163], Loss: 0.0343, Accuracy: 96.54%\n","Epoch [2/5], Step [38/163], Loss: 0.0345, Accuracy: 96.63%\n","Epoch [2/5], Step [39/163], Loss: 0.0352, Accuracy: 96.71%\n","Epoch [2/5], Step [40/163], Loss: 0.0354, Accuracy: 96.80%\n","Epoch [2/5], Step [41/163], Loss: 0.0356, Accuracy: 96.88%\n","Epoch [2/5], Step [42/163], Loss: 0.0361, Accuracy: 96.95%\n","Epoch [2/5], Step [43/163], Loss: 0.0376, Accuracy: 96.88%\n","Epoch [2/5], Step [44/163], Loss: 0.0381, Accuracy: 96.88%\n","Epoch [2/5], Step [45/163], Loss: 0.0390, Accuracy: 96.88%\n","Epoch [2/5], Step [46/163], Loss: 0.0395, Accuracy: 96.88%\n","Epoch [2/5], Step [47/163], Loss: 0.0398, Accuracy: 96.94%\n","Epoch [2/5], Step [48/163], Loss: 0.0399, Accuracy: 97.01%\n","Epoch [2/5], Step [49/163], Loss: 0.0407, Accuracy: 97.00%\n","Epoch [2/5], Step [50/163], Loss: 0.0409, Accuracy: 97.06%\n","Epoch [2/5], Step [51/163], Loss: 0.0437, Accuracy: 97.00%\n","Epoch [2/5], Step [52/163], Loss: 0.0440, Accuracy: 97.06%\n","Epoch [2/5], Step [53/163], Loss: 0.0456, Accuracy: 96.99%\n","Epoch [2/5], Step [54/163], Loss: 0.0470, Accuracy: 96.93%\n","Epoch [2/5], Step [55/163], Loss: 0.0483, Accuracy: 96.88%\n","Epoch [2/5], Step [56/163], Loss: 0.0485, Accuracy: 96.93%\n","Epoch [2/5], Step [57/163], Loss: 0.0488, Accuracy: 96.98%\n","Epoch [2/5], Step [58/163], Loss: 0.0495, Accuracy: 96.98%\n","Epoch [2/5], Step [59/163], Loss: 0.0511, Accuracy: 96.82%\n","Epoch [2/5], Step [60/163], Loss: 0.0529, Accuracy: 96.77%\n","Epoch [2/5], Step [61/163], Loss: 0.0533, Accuracy: 96.82%\n","Epoch [2/5], Step [62/163], Loss: 0.0536, Accuracy: 96.82%\n","Epoch [2/5], Step [63/163], Loss: 0.0540, Accuracy: 96.88%\n","Epoch [2/5], Step [64/163], Loss: 0.0545, Accuracy: 96.92%\n","Epoch [2/5], Step [65/163], Loss: 0.0548, Accuracy: 96.97%\n","Epoch [2/5], Step [66/163], Loss: 0.0552, Accuracy: 96.97%\n","Epoch [2/5], Step [67/163], Loss: 0.0564, Accuracy: 96.92%\n","Epoch [2/5], Step [68/163], Loss: 0.0573, Accuracy: 96.92%\n","Epoch [2/5], Step [69/163], Loss: 0.0575, Accuracy: 96.97%\n","Epoch [2/5], Step [70/163], Loss: 0.0578, Accuracy: 96.96%\n","Epoch [2/5], Step [71/163], Loss: 0.0581, Accuracy: 97.01%\n","Epoch [2/5], Step [72/163], Loss: 0.0582, Accuracy: 97.05%\n","Epoch [2/5], Step [73/163], Loss: 0.0586, Accuracy: 97.09%\n","Epoch [2/5], Step [74/163], Loss: 0.0588, Accuracy: 97.13%\n","Epoch [2/5], Step [75/163], Loss: 0.0594, Accuracy: 97.12%\n","Epoch [2/5], Step [76/163], Loss: 0.0610, Accuracy: 97.12%\n","Epoch [2/5], Step [77/163], Loss: 0.0616, Accuracy: 97.12%\n","Epoch [2/5], Step [78/163], Loss: 0.0617, Accuracy: 97.16%\n","Epoch [2/5], Step [79/163], Loss: 0.0625, Accuracy: 97.15%\n","Epoch [2/5], Step [80/163], Loss: 0.0632, Accuracy: 97.15%\n","Epoch [2/5], Step [81/163], Loss: 0.0638, Accuracy: 97.15%\n","Epoch [2/5], Step [82/163], Loss: 0.0649, Accuracy: 97.14%\n","Epoch [2/5], Step [83/163], Loss: 0.0663, Accuracy: 97.10%\n","Epoch [2/5], Step [84/163], Loss: 0.0665, Accuracy: 97.14%\n","Epoch [2/5], Step [85/163], Loss: 0.0667, Accuracy: 97.17%\n","Epoch [2/5], Step [86/163], Loss: 0.0668, Accuracy: 97.20%\n","Epoch [2/5], Step [87/163], Loss: 0.0681, Accuracy: 97.20%\n","Epoch [2/5], Step [88/163], Loss: 0.0694, Accuracy: 97.16%\n","Epoch [2/5], Step [89/163], Loss: 0.0710, Accuracy: 97.16%\n","Epoch [2/5], Step [90/163], Loss: 0.0726, Accuracy: 97.12%\n","Epoch [2/5], Step [91/163], Loss: 0.0740, Accuracy: 97.08%\n","Epoch [2/5], Step [92/163], Loss: 0.0741, Accuracy: 97.11%\n","Epoch [2/5], Step [93/163], Loss: 0.0765, Accuracy: 97.11%\n","Epoch [2/5], Step [94/163], Loss: 0.0766, Accuracy: 97.14%\n","Epoch [2/5], Step [95/163], Loss: 0.0768, Accuracy: 97.17%\n","Epoch [2/5], Step [96/163], Loss: 0.0773, Accuracy: 97.17%\n","Epoch [2/5], Step [97/163], Loss: 0.0786, Accuracy: 97.13%\n","Epoch [2/5], Step [98/163], Loss: 0.0789, Accuracy: 97.13%\n","Epoch [2/5], Step [99/163], Loss: 0.0795, Accuracy: 97.13%\n","Epoch [2/5], Step [100/163], Loss: 0.0832, Accuracy: 97.03%\n","Epoch [2/5], Step [101/163], Loss: 0.0843, Accuracy: 97.03%\n","Epoch [2/5], Step [102/163], Loss: 0.0848, Accuracy: 97.03%\n","Epoch [2/5], Step [103/163], Loss: 0.0850, Accuracy: 97.06%\n","Epoch [2/5], Step [104/163], Loss: 0.0870, Accuracy: 97.00%\n","Epoch [2/5], Step [105/163], Loss: 0.0875, Accuracy: 96.99%\n","Epoch [2/5], Step [106/163], Loss: 0.0885, Accuracy: 96.96%\n","Epoch [2/5], Step [107/163], Loss: 0.0888, Accuracy: 96.96%\n","Epoch [2/5], Step [108/163], Loss: 0.0894, Accuracy: 96.99%\n","Epoch [2/5], Step [109/163], Loss: 0.0896, Accuracy: 97.02%\n","Epoch [2/5], Step [110/163], Loss: 0.0899, Accuracy: 97.05%\n","Epoch [2/5], Step [111/163], Loss: 0.0901, Accuracy: 97.07%\n","Epoch [2/5], Step [112/163], Loss: 0.0908, Accuracy: 97.04%\n","Epoch [2/5], Step [113/163], Loss: 0.0912, Accuracy: 97.04%\n","Epoch [2/5], Step [114/163], Loss: 0.0926, Accuracy: 96.98%\n","Epoch [2/5], Step [115/163], Loss: 0.0927, Accuracy: 97.01%\n","Epoch [2/5], Step [116/163], Loss: 0.0930, Accuracy: 97.04%\n","Epoch [2/5], Step [117/163], Loss: 0.0954, Accuracy: 97.01%\n","Epoch [2/5], Step [118/163], Loss: 0.0959, Accuracy: 97.01%\n","Epoch [2/5], Step [119/163], Loss: 0.0965, Accuracy: 97.01%\n","Epoch [2/5], Step [120/163], Loss: 0.0970, Accuracy: 97.01%\n","Epoch [2/5], Step [121/163], Loss: 0.0982, Accuracy: 97.00%\n","Epoch [2/5], Step [122/163], Loss: 0.0996, Accuracy: 97.00%\n","Epoch [2/5], Step [123/163], Loss: 0.1000, Accuracy: 97.03%\n","Epoch [2/5], Step [124/163], Loss: 0.1013, Accuracy: 97.03%\n","Epoch [2/5], Step [125/163], Loss: 0.1019, Accuracy: 97.03%\n","Epoch [2/5], Step [126/163], Loss: 0.1107, Accuracy: 96.88%\n","Epoch [2/5], Step [127/163], Loss: 0.1118, Accuracy: 96.88%\n","Epoch [2/5], Step [128/163], Loss: 0.1124, Accuracy: 96.88%\n","Epoch [2/5], Step [129/163], Loss: 0.1135, Accuracy: 96.88%\n","Epoch [2/5], Step [130/163], Loss: 0.1140, Accuracy: 96.88%\n","Epoch [2/5], Step [131/163], Loss: 0.1165, Accuracy: 96.80%\n","Epoch [2/5], Step [132/163], Loss: 0.1204, Accuracy: 96.64%\n","Epoch [2/5], Step [133/163], Loss: 0.1211, Accuracy: 96.64%\n","Epoch [2/5], Step [134/163], Loss: 0.1229, Accuracy: 96.60%\n","Epoch [2/5], Step [135/163], Loss: 0.1231, Accuracy: 96.62%\n","Epoch [2/5], Step [136/163], Loss: 0.1235, Accuracy: 96.62%\n","Epoch [2/5], Step [137/163], Loss: 0.1238, Accuracy: 96.65%\n","Epoch [2/5], Step [138/163], Loss: 0.1245, Accuracy: 96.65%\n","Epoch [2/5], Step [139/163], Loss: 0.1255, Accuracy: 96.65%\n","Epoch [2/5], Step [140/163], Loss: 0.1280, Accuracy: 96.58%\n","Epoch [2/5], Step [141/163], Loss: 0.1283, Accuracy: 96.61%\n","Epoch [2/5], Step [142/163], Loss: 0.1288, Accuracy: 96.63%\n","Epoch [2/5], Step [143/163], Loss: 0.1290, Accuracy: 96.66%\n","Epoch [2/5], Step [144/163], Loss: 0.1293, Accuracy: 96.68%\n","Epoch [2/5], Step [145/163], Loss: 0.1297, Accuracy: 96.68%\n","Epoch [2/5], Step [146/163], Loss: 0.1299, Accuracy: 96.70%\n","Epoch [2/5], Step [147/163], Loss: 0.1303, Accuracy: 96.70%\n","Epoch [2/5], Step [148/163], Loss: 0.1323, Accuracy: 96.71%\n","Epoch [2/5], Step [149/163], Loss: 0.1326, Accuracy: 96.73%\n","Epoch [2/5], Step [150/163], Loss: 0.1337, Accuracy: 96.71%\n","Epoch [2/5], Step [151/163], Loss: 0.1349, Accuracy: 96.69%\n","Epoch [2/5], Step [152/163], Loss: 0.1369, Accuracy: 96.69%\n","Epoch [2/5], Step [153/163], Loss: 0.1372, Accuracy: 96.71%\n","Epoch [2/5], Step [154/163], Loss: 0.1389, Accuracy: 96.69%\n","Epoch [2/5], Step [155/163], Loss: 0.1413, Accuracy: 96.67%\n","Epoch [2/5], Step [156/163], Loss: 0.1415, Accuracy: 96.69%\n","Epoch [2/5], Step [157/163], Loss: 0.1427, Accuracy: 96.68%\n","Epoch [2/5], Step [158/163], Loss: 0.1443, Accuracy: 96.66%\n","Epoch [2/5], Step [159/163], Loss: 0.1445, Accuracy: 96.68%\n","Epoch [2/5], Step [160/163], Loss: 0.1449, Accuracy: 96.68%\n","Epoch [2/5], Step [161/163], Loss: 0.1455, Accuracy: 96.68%\n","Epoch [2/5], Step [162/163], Loss: 0.1466, Accuracy: 96.68%\n","Epoch [2/5], Step [163/163], Loss: 0.1495, Accuracy: 96.63%\n","Epoch [3/5], Step [1/163], Loss: 0.0003, Accuracy: 96.88%\n","Epoch [3/5], Step [2/163], Loss: 0.0011, Accuracy: 96.88%\n","Epoch [3/5], Step [3/163], Loss: 0.0016, Accuracy: 97.92%\n","Epoch [3/5], Step [4/163], Loss: 0.0035, Accuracy: 97.66%\n","Epoch [3/5], Step [5/163], Loss: 0.0047, Accuracy: 96.88%\n","Epoch [3/5], Step [6/163], Loss: 0.0049, Accuracy: 97.40%\n","Epoch [3/5], Step [7/163], Loss: 0.0055, Accuracy: 97.32%\n","Epoch [3/5], Step [8/163], Loss: 0.0060, Accuracy: 97.27%\n","Epoch [3/5], Step [9/163], Loss: 0.0065, Accuracy: 97.57%\n","Epoch [3/5], Step [10/163], Loss: 0.0069, Accuracy: 97.50%\n","Epoch [3/5], Step [11/163], Loss: 0.0092, Accuracy: 96.88%\n","Epoch [3/5], Step [12/163], Loss: 0.0097, Accuracy: 97.14%\n","Epoch [3/5], Step [13/163], Loss: 0.0100, Accuracy: 97.36%\n","Epoch [3/5], Step [14/163], Loss: 0.0101, Accuracy: 97.54%\n","Epoch [3/5], Step [15/163], Loss: 0.0102, Accuracy: 97.71%\n","Epoch [3/5], Step [16/163], Loss: 0.0112, Accuracy: 97.66%\n","Epoch [3/5], Step [17/163], Loss: 0.0127, Accuracy: 97.24%\n","Epoch [3/5], Step [18/163], Loss: 0.0132, Accuracy: 97.40%\n","Epoch [3/5], Step [19/163], Loss: 0.0135, Accuracy: 97.53%\n","Epoch [3/5], Step [20/163], Loss: 0.0141, Accuracy: 97.50%\n","Epoch [3/5], Step [21/163], Loss: 0.0143, Accuracy: 97.62%\n","Epoch [3/5], Step [22/163], Loss: 0.0161, Accuracy: 97.44%\n","Epoch [3/5], Step [23/163], Loss: 0.0171, Accuracy: 97.28%\n","Epoch [3/5], Step [24/163], Loss: 0.0195, Accuracy: 96.61%\n","Epoch [3/5], Step [25/163], Loss: 0.0207, Accuracy: 96.50%\n","Epoch [3/5], Step [26/163], Loss: 0.0212, Accuracy: 96.51%\n","Epoch [3/5], Step [27/163], Loss: 0.0214, Accuracy: 96.64%\n","Epoch [3/5], Step [28/163], Loss: 0.0217, Accuracy: 96.76%\n","Epoch [3/5], Step [29/163], Loss: 0.0218, Accuracy: 96.88%\n","Epoch [3/5], Step [30/163], Loss: 0.0234, Accuracy: 96.77%\n","Epoch [3/5], Step [31/163], Loss: 0.0253, Accuracy: 96.67%\n","Epoch [3/5], Step [32/163], Loss: 0.0257, Accuracy: 96.78%\n","Epoch [3/5], Step [33/163], Loss: 0.0260, Accuracy: 96.88%\n","Epoch [3/5], Step [34/163], Loss: 0.0280, Accuracy: 96.88%\n","Epoch [3/5], Step [35/163], Loss: 0.0291, Accuracy: 96.79%\n","Epoch [3/5], Step [36/163], Loss: 0.0293, Accuracy: 96.88%\n","Epoch [3/5], Step [37/163], Loss: 0.0295, Accuracy: 96.96%\n","Epoch [3/5], Step [38/163], Loss: 0.0304, Accuracy: 96.88%\n","Epoch [3/5], Step [39/163], Loss: 0.0306, Accuracy: 96.96%\n","Epoch [3/5], Step [40/163], Loss: 0.0328, Accuracy: 96.88%\n","Epoch [3/5], Step [41/163], Loss: 0.0344, Accuracy: 96.72%\n","Epoch [3/5], Step [42/163], Loss: 0.0351, Accuracy: 96.65%\n","Epoch [3/5], Step [43/163], Loss: 0.0361, Accuracy: 96.66%\n","Epoch [3/5], Step [44/163], Loss: 0.0375, Accuracy: 96.52%\n","Epoch [3/5], Step [45/163], Loss: 0.0382, Accuracy: 96.53%\n","Epoch [3/5], Step [46/163], Loss: 0.0385, Accuracy: 96.60%\n","Epoch [3/5], Step [47/163], Loss: 0.0391, Accuracy: 96.61%\n","Epoch [3/5], Step [48/163], Loss: 0.0395, Accuracy: 96.61%\n","Epoch [3/5], Step [49/163], Loss: 0.0413, Accuracy: 96.49%\n","Epoch [3/5], Step [50/163], Loss: 0.0414, Accuracy: 96.56%\n","Epoch [3/5], Step [51/163], Loss: 0.0417, Accuracy: 96.63%\n","Epoch [3/5], Step [52/163], Loss: 0.0432, Accuracy: 96.57%\n","Epoch [3/5], Step [53/163], Loss: 0.0433, Accuracy: 96.64%\n","Epoch [3/5], Step [54/163], Loss: 0.0446, Accuracy: 96.59%\n","Epoch [3/5], Step [55/163], Loss: 0.0447, Accuracy: 96.65%\n","Epoch [3/5], Step [56/163], Loss: 0.0458, Accuracy: 96.65%\n","Epoch [3/5], Step [57/163], Loss: 0.0466, Accuracy: 96.60%\n","Epoch [3/5], Step [58/163], Loss: 0.0472, Accuracy: 96.61%\n","Epoch [3/5], Step [59/163], Loss: 0.0475, Accuracy: 96.66%\n","Epoch [3/5], Step [60/163], Loss: 0.0476, Accuracy: 96.72%\n","Epoch [3/5], Step [61/163], Loss: 0.0480, Accuracy: 96.77%\n","Epoch [3/5], Step [62/163], Loss: 0.0492, Accuracy: 96.77%\n","Epoch [3/5], Step [63/163], Loss: 0.0505, Accuracy: 96.73%\n","Epoch [3/5], Step [64/163], Loss: 0.0534, Accuracy: 96.63%\n","Epoch [3/5], Step [65/163], Loss: 0.0543, Accuracy: 96.63%\n","Epoch [3/5], Step [66/163], Loss: 0.0550, Accuracy: 96.64%\n","Epoch [3/5], Step [67/163], Loss: 0.0555, Accuracy: 96.64%\n","Epoch [3/5], Step [68/163], Loss: 0.0560, Accuracy: 96.65%\n","Epoch [3/5], Step [69/163], Loss: 0.0569, Accuracy: 96.65%\n","Epoch [3/5], Step [70/163], Loss: 0.0605, Accuracy: 96.47%\n","Epoch [3/5], Step [71/163], Loss: 0.0606, Accuracy: 96.52%\n","Epoch [3/5], Step [72/163], Loss: 0.0635, Accuracy: 96.44%\n","Epoch [3/5], Step [73/163], Loss: 0.0674, Accuracy: 96.36%\n","Epoch [3/5], Step [74/163], Loss: 0.0676, Accuracy: 96.41%\n","Epoch [3/5], Step [75/163], Loss: 0.0687, Accuracy: 96.42%\n","Epoch [3/5], Step [76/163], Loss: 0.0698, Accuracy: 96.42%\n","Epoch [3/5], Step [77/163], Loss: 0.0700, Accuracy: 96.47%\n","Epoch [3/5], Step [78/163], Loss: 0.0701, Accuracy: 96.51%\n","Epoch [3/5], Step [79/163], Loss: 0.0717, Accuracy: 96.48%\n","Epoch [3/5], Step [80/163], Loss: 0.0728, Accuracy: 96.48%\n","Epoch [3/5], Step [81/163], Loss: 0.0747, Accuracy: 96.49%\n","Epoch [3/5], Step [82/163], Loss: 0.0756, Accuracy: 96.49%\n","Epoch [3/5], Step [83/163], Loss: 0.0772, Accuracy: 96.46%\n","Epoch [3/5], Step [84/163], Loss: 0.0774, Accuracy: 96.50%\n","Epoch [3/5], Step [85/163], Loss: 0.0777, Accuracy: 96.54%\n","Epoch [3/5], Step [86/163], Loss: 0.0798, Accuracy: 96.48%\n","Epoch [3/5], Step [87/163], Loss: 0.0824, Accuracy: 96.41%\n","Epoch [3/5], Step [88/163], Loss: 0.0828, Accuracy: 96.41%\n","Epoch [3/5], Step [89/163], Loss: 0.0830, Accuracy: 96.45%\n","Epoch [3/5], Step [90/163], Loss: 0.0850, Accuracy: 96.39%\n","Epoch [3/5], Step [91/163], Loss: 0.0854, Accuracy: 96.43%\n","Epoch [3/5], Step [92/163], Loss: 0.0858, Accuracy: 96.47%\n","Epoch [3/5], Step [93/163], Loss: 0.0865, Accuracy: 96.47%\n","Epoch [3/5], Step [94/163], Loss: 0.0868, Accuracy: 96.51%\n","Epoch [3/5], Step [95/163], Loss: 0.0874, Accuracy: 96.55%\n","Epoch [3/5], Step [96/163], Loss: 0.0893, Accuracy: 96.52%\n","Epoch [3/5], Step [97/163], Loss: 0.0900, Accuracy: 96.52%\n","Epoch [3/5], Step [98/163], Loss: 0.0921, Accuracy: 96.49%\n","Epoch [3/5], Step [99/163], Loss: 0.0926, Accuracy: 96.50%\n","Epoch [3/5], Step [100/163], Loss: 0.0933, Accuracy: 96.50%\n","Epoch [3/5], Step [101/163], Loss: 0.0933, Accuracy: 96.53%\n","Epoch [3/5], Step [102/163], Loss: 0.0934, Accuracy: 96.57%\n","Epoch [3/5], Step [103/163], Loss: 0.0939, Accuracy: 96.57%\n","Epoch [3/5], Step [104/163], Loss: 0.0944, Accuracy: 96.57%\n","Epoch [3/5], Step [105/163], Loss: 0.0947, Accuracy: 96.61%\n","Epoch [3/5], Step [106/163], Loss: 0.0948, Accuracy: 96.64%\n","Epoch [3/5], Step [107/163], Loss: 0.0950, Accuracy: 96.67%\n","Epoch [3/5], Step [108/163], Loss: 0.0970, Accuracy: 96.64%\n","Epoch [3/5], Step [109/163], Loss: 0.0974, Accuracy: 96.67%\n","Epoch [3/5], Step [110/163], Loss: 0.0977, Accuracy: 96.70%\n","Epoch [3/5], Step [111/163], Loss: 0.0990, Accuracy: 96.65%\n","Epoch [3/5], Step [112/163], Loss: 0.1002, Accuracy: 96.65%\n","Epoch [3/5], Step [113/163], Loss: 0.1018, Accuracy: 96.60%\n","Epoch [3/5], Step [114/163], Loss: 0.1021, Accuracy: 96.63%\n","Epoch [3/5], Step [115/163], Loss: 0.1023, Accuracy: 96.66%\n","Epoch [3/5], Step [116/163], Loss: 0.1024, Accuracy: 96.69%\n","Epoch [3/5], Step [117/163], Loss: 0.1046, Accuracy: 96.66%\n","Epoch [3/5], Step [118/163], Loss: 0.1058, Accuracy: 96.64%\n","Epoch [3/5], Step [119/163], Loss: 0.1091, Accuracy: 96.61%\n","Epoch [3/5], Step [120/163], Loss: 0.1094, Accuracy: 96.64%\n","Epoch [3/5], Step [121/163], Loss: 0.1101, Accuracy: 96.64%\n","Epoch [3/5], Step [122/163], Loss: 0.1103, Accuracy: 96.67%\n","Epoch [3/5], Step [123/163], Loss: 0.1110, Accuracy: 96.67%\n","Epoch [3/5], Step [124/163], Loss: 0.1122, Accuracy: 96.67%\n","Epoch [3/5], Step [125/163], Loss: 0.1141, Accuracy: 96.65%\n","Epoch [3/5], Step [126/163], Loss: 0.1164, Accuracy: 96.60%\n","Epoch [3/5], Step [127/163], Loss: 0.1165, Accuracy: 96.63%\n","Epoch [3/5], Step [128/163], Loss: 0.1168, Accuracy: 96.66%\n","Epoch [3/5], Step [129/163], Loss: 0.1173, Accuracy: 96.66%\n","Epoch [3/5], Step [130/163], Loss: 0.1176, Accuracy: 96.66%\n","Epoch [3/5], Step [131/163], Loss: 0.1187, Accuracy: 96.64%\n","Epoch [3/5], Step [132/163], Loss: 0.1203, Accuracy: 96.61%\n","Epoch [3/5], Step [133/163], Loss: 0.1205, Accuracy: 96.64%\n","Epoch [3/5], Step [134/163], Loss: 0.1210, Accuracy: 96.64%\n","Epoch [3/5], Step [135/163], Loss: 0.1212, Accuracy: 96.67%\n","Epoch [3/5], Step [136/163], Loss: 0.1214, Accuracy: 96.69%\n","Epoch [3/5], Step [137/163], Loss: 0.1229, Accuracy: 96.69%\n","Epoch [3/5], Step [138/163], Loss: 0.1242, Accuracy: 96.65%\n","Epoch [3/5], Step [139/163], Loss: 0.1255, Accuracy: 96.65%\n","Epoch [3/5], Step [140/163], Loss: 0.1269, Accuracy: 96.63%\n","Epoch [3/5], Step [141/163], Loss: 0.1282, Accuracy: 96.63%\n","Epoch [3/5], Step [142/163], Loss: 0.1298, Accuracy: 96.63%\n","Epoch [3/5], Step [143/163], Loss: 0.1301, Accuracy: 96.66%\n","Epoch [3/5], Step [144/163], Loss: 0.1308, Accuracy: 96.66%\n","Epoch [3/5], Step [145/163], Loss: 0.1312, Accuracy: 96.66%\n","Epoch [3/5], Step [146/163], Loss: 0.1314, Accuracy: 96.68%\n","Epoch [3/5], Step [147/163], Loss: 0.1325, Accuracy: 96.68%\n","Epoch [3/5], Step [148/163], Loss: 0.1332, Accuracy: 96.68%\n","Epoch [3/5], Step [149/163], Loss: 0.1336, Accuracy: 96.71%\n","Epoch [3/5], Step [150/163], Loss: 0.1341, Accuracy: 96.71%\n","Epoch [3/5], Step [151/163], Loss: 0.1354, Accuracy: 96.69%\n","Epoch [3/5], Step [152/163], Loss: 0.1367, Accuracy: 96.69%\n","Epoch [3/5], Step [153/163], Loss: 0.1374, Accuracy: 96.69%\n","Epoch [3/5], Step [154/163], Loss: 0.1386, Accuracy: 96.69%\n","Epoch [3/5], Step [155/163], Loss: 0.1400, Accuracy: 96.67%\n","Epoch [3/5], Step [156/163], Loss: 0.1413, Accuracy: 96.67%\n","Epoch [3/5], Step [157/163], Loss: 0.1424, Accuracy: 96.68%\n","Epoch [3/5], Step [158/163], Loss: 0.1435, Accuracy: 96.68%\n","Epoch [3/5], Step [159/163], Loss: 0.1438, Accuracy: 96.70%\n","Epoch [3/5], Step [160/163], Loss: 0.1441, Accuracy: 96.72%\n","Epoch [3/5], Step [161/163], Loss: 0.1452, Accuracy: 96.72%\n","Epoch [3/5], Step [162/163], Loss: 0.1462, Accuracy: 96.72%\n","Epoch [3/5], Step [163/163], Loss: 0.1468, Accuracy: 96.72%\n","Epoch [4/5], Step [1/163], Loss: 0.0012, Accuracy: 96.88%\n","Epoch [4/5], Step [2/163], Loss: 0.0016, Accuracy: 98.44%\n","Epoch [4/5], Step [3/163], Loss: 0.0019, Accuracy: 98.96%\n","Epoch [4/5], Step [4/163], Loss: 0.0033, Accuracy: 98.44%\n","Epoch [4/5], Step [5/163], Loss: 0.0037, Accuracy: 98.75%\n","Epoch [4/5], Step [6/163], Loss: 0.0041, Accuracy: 98.96%\n","Epoch [4/5], Step [7/163], Loss: 0.0045, Accuracy: 99.11%\n","Epoch [4/5], Step [8/163], Loss: 0.0072, Accuracy: 98.44%\n","Epoch [4/5], Step [9/163], Loss: 0.0073, Accuracy: 98.61%\n","Epoch [4/5], Step [10/163], Loss: 0.0080, Accuracy: 98.44%\n","Epoch [4/5], Step [11/163], Loss: 0.0087, Accuracy: 98.30%\n","Epoch [4/5], Step [12/163], Loss: 0.0092, Accuracy: 98.44%\n","Epoch [4/5], Step [13/163], Loss: 0.0094, Accuracy: 98.56%\n","Epoch [4/5], Step [14/163], Loss: 0.0096, Accuracy: 98.66%\n","Epoch [4/5], Step [15/163], Loss: 0.0112, Accuracy: 98.33%\n","Epoch [4/5], Step [16/163], Loss: 0.0114, Accuracy: 98.44%\n","Epoch [4/5], Step [17/163], Loss: 0.0123, Accuracy: 98.35%\n","Epoch [4/5], Step [18/163], Loss: 0.0126, Accuracy: 98.44%\n","Epoch [4/5], Step [19/163], Loss: 0.0132, Accuracy: 98.36%\n","Epoch [4/5], Step [20/163], Loss: 0.0150, Accuracy: 98.28%\n","Epoch [4/5], Step [21/163], Loss: 0.0151, Accuracy: 98.36%\n","Epoch [4/5], Step [22/163], Loss: 0.0158, Accuracy: 98.30%\n","Epoch [4/5], Step [23/163], Loss: 0.0160, Accuracy: 98.37%\n","Epoch [4/5], Step [24/163], Loss: 0.0162, Accuracy: 98.44%\n","Epoch [4/5], Step [25/163], Loss: 0.0168, Accuracy: 98.38%\n","Epoch [4/5], Step [26/163], Loss: 0.0168, Accuracy: 98.44%\n","Epoch [4/5], Step [27/163], Loss: 0.0169, Accuracy: 98.50%\n","Epoch [4/5], Step [28/163], Loss: 0.0170, Accuracy: 98.55%\n","Epoch [4/5], Step [29/163], Loss: 0.0172, Accuracy: 98.60%\n","Epoch [4/5], Step [30/163], Loss: 0.0173, Accuracy: 98.65%\n","Epoch [4/5], Step [31/163], Loss: 0.0181, Accuracy: 98.59%\n","Epoch [4/5], Step [32/163], Loss: 0.0193, Accuracy: 98.54%\n","Epoch [4/5], Step [33/163], Loss: 0.0196, Accuracy: 98.48%\n","Epoch [4/5], Step [34/163], Loss: 0.0204, Accuracy: 98.44%\n","Epoch [4/5], Step [35/163], Loss: 0.0218, Accuracy: 98.39%\n","Epoch [4/5], Step [36/163], Loss: 0.0228, Accuracy: 98.35%\n","Epoch [4/5], Step [37/163], Loss: 0.0229, Accuracy: 98.40%\n","Epoch [4/5], Step [38/163], Loss: 0.0230, Accuracy: 98.44%\n","Epoch [4/5], Step [39/163], Loss: 0.0240, Accuracy: 98.32%\n","Epoch [4/5], Step [40/163], Loss: 0.0249, Accuracy: 98.28%\n","Epoch [4/5], Step [41/163], Loss: 0.0251, Accuracy: 98.32%\n","Epoch [4/5], Step [42/163], Loss: 0.0260, Accuracy: 98.29%\n","Epoch [4/5], Step [43/163], Loss: 0.0267, Accuracy: 98.26%\n","Epoch [4/5], Step [44/163], Loss: 0.0278, Accuracy: 98.15%\n","Epoch [4/5], Step [45/163], Loss: 0.0279, Accuracy: 98.19%\n","Epoch [4/5], Step [46/163], Loss: 0.0279, Accuracy: 98.23%\n","Epoch [4/5], Step [47/163], Loss: 0.0280, Accuracy: 98.27%\n","Epoch [4/5], Step [48/163], Loss: 0.0298, Accuracy: 97.98%\n","Epoch [4/5], Step [49/163], Loss: 0.0303, Accuracy: 98.02%\n","Epoch [4/5], Step [50/163], Loss: 0.0316, Accuracy: 98.00%\n","Epoch [4/5], Step [51/163], Loss: 0.0329, Accuracy: 97.92%\n","Epoch [4/5], Step [52/163], Loss: 0.0333, Accuracy: 97.96%\n","Epoch [4/5], Step [53/163], Loss: 0.0339, Accuracy: 97.94%\n","Epoch [4/5], Step [54/163], Loss: 0.0354, Accuracy: 97.92%\n","Epoch [4/5], Step [55/163], Loss: 0.0357, Accuracy: 97.90%\n","Epoch [4/5], Step [56/163], Loss: 0.0360, Accuracy: 97.88%\n","Epoch [4/5], Step [57/163], Loss: 0.0361, Accuracy: 97.92%\n","Epoch [4/5], Step [58/163], Loss: 0.0365, Accuracy: 97.95%\n","Epoch [4/5], Step [59/163], Loss: 0.0376, Accuracy: 97.93%\n","Epoch [4/5], Step [60/163], Loss: 0.0396, Accuracy: 97.81%\n","Epoch [4/5], Step [61/163], Loss: 0.0405, Accuracy: 97.75%\n","Epoch [4/5], Step [62/163], Loss: 0.0419, Accuracy: 97.73%\n","Epoch [4/5], Step [63/163], Loss: 0.0424, Accuracy: 97.72%\n","Epoch [4/5], Step [64/163], Loss: 0.0429, Accuracy: 97.71%\n","Epoch [4/5], Step [65/163], Loss: 0.0436, Accuracy: 97.69%\n","Epoch [4/5], Step [66/163], Loss: 0.0445, Accuracy: 97.63%\n","Epoch [4/5], Step [67/163], Loss: 0.0450, Accuracy: 97.67%\n","Epoch [4/5], Step [68/163], Loss: 0.0455, Accuracy: 97.66%\n","Epoch [4/5], Step [69/163], Loss: 0.0456, Accuracy: 97.69%\n","Epoch [4/5], Step [70/163], Loss: 0.0464, Accuracy: 97.68%\n","Epoch [4/5], Step [71/163], Loss: 0.0468, Accuracy: 97.67%\n","Epoch [4/5], Step [72/163], Loss: 0.0473, Accuracy: 97.66%\n","Epoch [4/5], Step [73/163], Loss: 0.0476, Accuracy: 97.65%\n","Epoch [4/5], Step [74/163], Loss: 0.0477, Accuracy: 97.68%\n","Epoch [4/5], Step [75/163], Loss: 0.0483, Accuracy: 97.71%\n","Epoch [4/5], Step [76/163], Loss: 0.0503, Accuracy: 97.62%\n","Epoch [4/5], Step [77/163], Loss: 0.0505, Accuracy: 97.65%\n","Epoch [4/5], Step [78/163], Loss: 0.0507, Accuracy: 97.68%\n","Epoch [4/5], Step [79/163], Loss: 0.0535, Accuracy: 97.55%\n","Epoch [4/5], Step [80/163], Loss: 0.0536, Accuracy: 97.58%\n","Epoch [4/5], Step [81/163], Loss: 0.0550, Accuracy: 97.53%\n","Epoch [4/5], Step [82/163], Loss: 0.0555, Accuracy: 97.52%\n","Epoch [4/5], Step [83/163], Loss: 0.0559, Accuracy: 97.55%\n","Epoch [4/5], Step [84/163], Loss: 0.0565, Accuracy: 97.54%\n","Epoch [4/5], Step [85/163], Loss: 0.0568, Accuracy: 97.57%\n","Epoch [4/5], Step [86/163], Loss: 0.0571, Accuracy: 97.60%\n","Epoch [4/5], Step [87/163], Loss: 0.0584, Accuracy: 97.59%\n","Epoch [4/5], Step [88/163], Loss: 0.0588, Accuracy: 97.62%\n","Epoch [4/5], Step [89/163], Loss: 0.0590, Accuracy: 97.65%\n","Epoch [4/5], Step [90/163], Loss: 0.0597, Accuracy: 97.60%\n","Epoch [4/5], Step [91/163], Loss: 0.0613, Accuracy: 97.60%\n","Epoch [4/5], Step [92/163], Loss: 0.0622, Accuracy: 97.59%\n","Epoch [4/5], Step [93/163], Loss: 0.0645, Accuracy: 97.55%\n","Epoch [4/5], Step [94/163], Loss: 0.0653, Accuracy: 97.54%\n","Epoch [4/5], Step [95/163], Loss: 0.0655, Accuracy: 97.57%\n","Epoch [4/5], Step [96/163], Loss: 0.0655, Accuracy: 97.59%\n","Epoch [4/5], Step [97/163], Loss: 0.0656, Accuracy: 97.62%\n","Epoch [4/5], Step [98/163], Loss: 0.0659, Accuracy: 97.64%\n","Epoch [4/5], Step [99/163], Loss: 0.0662, Accuracy: 97.66%\n","Epoch [4/5], Step [100/163], Loss: 0.0667, Accuracy: 97.69%\n","Epoch [4/5], Step [101/163], Loss: 0.0672, Accuracy: 97.68%\n","Epoch [4/5], Step [102/163], Loss: 0.0698, Accuracy: 97.61%\n","Epoch [4/5], Step [103/163], Loss: 0.0699, Accuracy: 97.63%\n","Epoch [4/5], Step [104/163], Loss: 0.0710, Accuracy: 97.57%\n","Epoch [4/5], Step [105/163], Loss: 0.0716, Accuracy: 97.53%\n","Epoch [4/5], Step [106/163], Loss: 0.0721, Accuracy: 97.52%\n","Epoch [4/5], Step [107/163], Loss: 0.0734, Accuracy: 97.49%\n","Epoch [4/5], Step [108/163], Loss: 0.0752, Accuracy: 97.45%\n","Epoch [4/5], Step [109/163], Loss: 0.0764, Accuracy: 97.45%\n","Epoch [4/5], Step [110/163], Loss: 0.0770, Accuracy: 97.44%\n","Epoch [4/5], Step [111/163], Loss: 0.0781, Accuracy: 97.44%\n","Epoch [4/5], Step [112/163], Loss: 0.0801, Accuracy: 97.41%\n","Epoch [4/5], Step [113/163], Loss: 0.0805, Accuracy: 97.40%\n","Epoch [4/5], Step [114/163], Loss: 0.0812, Accuracy: 97.40%\n","Epoch [4/5], Step [115/163], Loss: 0.0817, Accuracy: 97.42%\n","Epoch [4/5], Step [116/163], Loss: 0.0825, Accuracy: 97.39%\n","Epoch [4/5], Step [117/163], Loss: 0.0836, Accuracy: 97.36%\n","Epoch [4/5], Step [118/163], Loss: 0.0840, Accuracy: 97.38%\n","Epoch [4/5], Step [119/163], Loss: 0.0846, Accuracy: 97.37%\n","Epoch [4/5], Step [120/163], Loss: 0.0856, Accuracy: 97.34%\n","Epoch [4/5], Step [121/163], Loss: 0.0861, Accuracy: 97.37%\n","Epoch [4/5], Step [122/163], Loss: 0.0864, Accuracy: 97.39%\n","Epoch [4/5], Step [123/163], Loss: 0.0865, Accuracy: 97.41%\n","Epoch [4/5], Step [124/163], Loss: 0.0872, Accuracy: 97.40%\n","Epoch [4/5], Step [125/163], Loss: 0.0876, Accuracy: 97.40%\n","Epoch [4/5], Step [126/163], Loss: 0.0883, Accuracy: 97.37%\n","Epoch [4/5], Step [127/163], Loss: 0.0885, Accuracy: 97.39%\n","Epoch [4/5], Step [128/163], Loss: 0.0914, Accuracy: 97.36%\n","Epoch [4/5], Step [129/163], Loss: 0.0927, Accuracy: 97.34%\n","Epoch [4/5], Step [130/163], Loss: 0.0929, Accuracy: 97.36%\n","Epoch [4/5], Step [131/163], Loss: 0.0931, Accuracy: 97.38%\n","Epoch [4/5], Step [132/163], Loss: 0.0940, Accuracy: 97.35%\n","Epoch [4/5], Step [133/163], Loss: 0.0946, Accuracy: 97.34%\n","Epoch [4/5], Step [134/163], Loss: 0.0951, Accuracy: 97.34%\n","Epoch [4/5], Step [135/163], Loss: 0.0954, Accuracy: 97.36%\n","Epoch [4/5], Step [136/163], Loss: 0.0958, Accuracy: 97.36%\n","Epoch [4/5], Step [137/163], Loss: 0.0960, Accuracy: 97.38%\n","Epoch [4/5], Step [138/163], Loss: 0.0966, Accuracy: 97.37%\n","Epoch [4/5], Step [139/163], Loss: 0.0967, Accuracy: 97.39%\n","Epoch [4/5], Step [140/163], Loss: 0.0972, Accuracy: 97.41%\n","Epoch [4/5], Step [141/163], Loss: 0.0973, Accuracy: 97.43%\n","Epoch [4/5], Step [142/163], Loss: 0.0989, Accuracy: 97.40%\n","Epoch [4/5], Step [143/163], Loss: 0.1000, Accuracy: 97.40%\n","Epoch [4/5], Step [144/163], Loss: 0.1004, Accuracy: 97.40%\n","Epoch [4/5], Step [145/163], Loss: 0.1009, Accuracy: 97.39%\n","Epoch [4/5], Step [146/163], Loss: 0.1010, Accuracy: 97.41%\n","Epoch [4/5], Step [147/163], Loss: 0.1018, Accuracy: 97.41%\n","Epoch [4/5], Step [148/163], Loss: 0.1020, Accuracy: 97.42%\n","Epoch [4/5], Step [149/163], Loss: 0.1023, Accuracy: 97.44%\n","Epoch [4/5], Step [150/163], Loss: 0.1024, Accuracy: 97.46%\n","Epoch [4/5], Step [151/163], Loss: 0.1042, Accuracy: 97.45%\n","Epoch [4/5], Step [152/163], Loss: 0.1047, Accuracy: 97.45%\n","Epoch [4/5], Step [153/163], Loss: 0.1059, Accuracy: 97.45%\n","Epoch [4/5], Step [154/163], Loss: 0.1061, Accuracy: 97.46%\n","Epoch [4/5], Step [155/163], Loss: 0.1085, Accuracy: 97.42%\n","Epoch [4/5], Step [156/163], Loss: 0.1086, Accuracy: 97.44%\n","Epoch [4/5], Step [157/163], Loss: 0.1087, Accuracy: 97.45%\n","Epoch [4/5], Step [158/163], Loss: 0.1092, Accuracy: 97.47%\n","Epoch [4/5], Step [159/163], Loss: 0.1098, Accuracy: 97.46%\n","Epoch [4/5], Step [160/163], Loss: 0.1099, Accuracy: 97.48%\n","Epoch [4/5], Step [161/163], Loss: 0.1103, Accuracy: 97.50%\n","Epoch [4/5], Step [162/163], Loss: 0.1108, Accuracy: 97.49%\n","Epoch [4/5], Step [163/163], Loss: 0.1114, Accuracy: 97.49%\n","Epoch [5/5], Step [1/163], Loss: 0.0013, Accuracy: 93.75%\n","Epoch [5/5], Step [2/163], Loss: 0.0018, Accuracy: 96.88%\n","Epoch [5/5], Step [3/163], Loss: 0.0021, Accuracy: 97.92%\n","Epoch [5/5], Step [4/163], Loss: 0.0040, Accuracy: 96.88%\n","Epoch [5/5], Step [5/163], Loss: 0.0046, Accuracy: 96.88%\n","Epoch [5/5], Step [6/163], Loss: 0.0053, Accuracy: 96.88%\n","Epoch [5/5], Step [7/163], Loss: 0.0055, Accuracy: 97.32%\n","Epoch [5/5], Step [8/163], Loss: 0.0060, Accuracy: 97.66%\n","Epoch [5/5], Step [9/163], Loss: 0.0072, Accuracy: 97.57%\n","Epoch [5/5], Step [10/163], Loss: 0.0078, Accuracy: 97.50%\n","Epoch [5/5], Step [11/163], Loss: 0.0083, Accuracy: 97.73%\n","Epoch [5/5], Step [12/163], Loss: 0.0084, Accuracy: 97.92%\n","Epoch [5/5], Step [13/163], Loss: 0.0087, Accuracy: 98.08%\n","Epoch [5/5], Step [14/163], Loss: 0.0088, Accuracy: 98.21%\n","Epoch [5/5], Step [15/163], Loss: 0.0089, Accuracy: 98.33%\n","Epoch [5/5], Step [16/163], Loss: 0.0111, Accuracy: 98.24%\n","Epoch [5/5], Step [17/163], Loss: 0.0111, Accuracy: 98.35%\n","Epoch [5/5], Step [18/163], Loss: 0.0120, Accuracy: 98.26%\n","Epoch [5/5], Step [19/163], Loss: 0.0121, Accuracy: 98.36%\n","Epoch [5/5], Step [20/163], Loss: 0.0127, Accuracy: 98.28%\n","Epoch [5/5], Step [21/163], Loss: 0.0143, Accuracy: 97.92%\n","Epoch [5/5], Step [22/163], Loss: 0.0153, Accuracy: 97.73%\n","Epoch [5/5], Step [23/163], Loss: 0.0164, Accuracy: 97.69%\n","Epoch [5/5], Step [24/163], Loss: 0.0171, Accuracy: 97.66%\n","Epoch [5/5], Step [25/163], Loss: 0.0174, Accuracy: 97.62%\n","Epoch [5/5], Step [26/163], Loss: 0.0177, Accuracy: 97.72%\n","Epoch [5/5], Step [27/163], Loss: 0.0179, Accuracy: 97.80%\n","Epoch [5/5], Step [28/163], Loss: 0.0181, Accuracy: 97.88%\n","Epoch [5/5], Step [29/163], Loss: 0.0182, Accuracy: 97.95%\n","Epoch [5/5], Step [30/163], Loss: 0.0184, Accuracy: 98.02%\n","Epoch [5/5], Step [31/163], Loss: 0.0190, Accuracy: 97.98%\n","Epoch [5/5], Step [32/163], Loss: 0.0195, Accuracy: 97.95%\n","Epoch [5/5], Step [33/163], Loss: 0.0204, Accuracy: 97.92%\n","Epoch [5/5], Step [34/163], Loss: 0.0205, Accuracy: 97.98%\n","Epoch [5/5], Step [35/163], Loss: 0.0207, Accuracy: 98.04%\n","Epoch [5/5], Step [36/163], Loss: 0.0210, Accuracy: 98.00%\n","Epoch [5/5], Step [37/163], Loss: 0.0213, Accuracy: 98.06%\n","Epoch [5/5], Step [38/163], Loss: 0.0214, Accuracy: 98.11%\n","Epoch [5/5], Step [39/163], Loss: 0.0221, Accuracy: 98.08%\n","Epoch [5/5], Step [40/163], Loss: 0.0227, Accuracy: 98.12%\n","Epoch [5/5], Step [41/163], Loss: 0.0235, Accuracy: 98.09%\n","Epoch [5/5], Step [42/163], Loss: 0.0236, Accuracy: 98.14%\n","Epoch [5/5], Step [43/163], Loss: 0.0240, Accuracy: 98.11%\n","Epoch [5/5], Step [44/163], Loss: 0.0244, Accuracy: 98.08%\n","Epoch [5/5], Step [45/163], Loss: 0.0246, Accuracy: 98.12%\n","Epoch [5/5], Step [46/163], Loss: 0.0253, Accuracy: 98.10%\n","Epoch [5/5], Step [47/163], Loss: 0.0255, Accuracy: 98.14%\n","Epoch [5/5], Step [48/163], Loss: 0.0264, Accuracy: 98.05%\n","Epoch [5/5], Step [49/163], Loss: 0.0283, Accuracy: 98.02%\n","Epoch [5/5], Step [50/163], Loss: 0.0297, Accuracy: 97.88%\n","Epoch [5/5], Step [51/163], Loss: 0.0309, Accuracy: 97.86%\n","Epoch [5/5], Step [52/163], Loss: 0.0309, Accuracy: 97.90%\n","Epoch [5/5], Step [53/163], Loss: 0.0310, Accuracy: 97.94%\n","Epoch [5/5], Step [54/163], Loss: 0.0318, Accuracy: 97.92%\n","Epoch [5/5], Step [55/163], Loss: 0.0324, Accuracy: 97.90%\n","Epoch [5/5], Step [56/163], Loss: 0.0325, Accuracy: 97.94%\n","Epoch [5/5], Step [57/163], Loss: 0.0333, Accuracy: 97.92%\n","Epoch [5/5], Step [58/163], Loss: 0.0334, Accuracy: 97.95%\n","Epoch [5/5], Step [59/163], Loss: 0.0353, Accuracy: 97.88%\n","Epoch [5/5], Step [60/163], Loss: 0.0354, Accuracy: 97.92%\n","Epoch [5/5], Step [61/163], Loss: 0.0361, Accuracy: 97.90%\n","Epoch [5/5], Step [62/163], Loss: 0.0378, Accuracy: 97.83%\n","Epoch [5/5], Step [63/163], Loss: 0.0379, Accuracy: 97.87%\n","Epoch [5/5], Step [64/163], Loss: 0.0390, Accuracy: 97.85%\n","Epoch [5/5], Step [65/163], Loss: 0.0406, Accuracy: 97.74%\n","Epoch [5/5], Step [66/163], Loss: 0.0410, Accuracy: 97.73%\n","Epoch [5/5], Step [67/163], Loss: 0.0412, Accuracy: 97.76%\n","Epoch [5/5], Step [68/163], Loss: 0.0416, Accuracy: 97.79%\n","Epoch [5/5], Step [69/163], Loss: 0.0426, Accuracy: 97.69%\n","Epoch [5/5], Step [70/163], Loss: 0.0429, Accuracy: 97.72%\n","Epoch [5/5], Step [71/163], Loss: 0.0435, Accuracy: 97.71%\n","Epoch [5/5], Step [72/163], Loss: 0.0441, Accuracy: 97.66%\n","Epoch [5/5], Step [73/163], Loss: 0.0445, Accuracy: 97.69%\n","Epoch [5/5], Step [74/163], Loss: 0.0451, Accuracy: 97.68%\n","Epoch [5/5], Step [75/163], Loss: 0.0456, Accuracy: 97.67%\n","Epoch [5/5], Step [76/163], Loss: 0.0457, Accuracy: 97.70%\n","Epoch [5/5], Step [77/163], Loss: 0.0458, Accuracy: 97.73%\n","Epoch [5/5], Step [78/163], Loss: 0.0465, Accuracy: 97.72%\n","Epoch [5/5], Step [79/163], Loss: 0.0466, Accuracy: 97.75%\n","Epoch [5/5], Step [80/163], Loss: 0.0469, Accuracy: 97.77%\n","Epoch [5/5], Step [81/163], Loss: 0.0477, Accuracy: 97.72%\n","Epoch [5/5], Step [82/163], Loss: 0.0488, Accuracy: 97.71%\n","Epoch [5/5], Step [83/163], Loss: 0.0490, Accuracy: 97.74%\n","Epoch [5/5], Step [84/163], Loss: 0.0493, Accuracy: 97.77%\n","Epoch [5/5], Step [85/163], Loss: 0.0498, Accuracy: 97.76%\n","Epoch [5/5], Step [86/163], Loss: 0.0500, Accuracy: 97.78%\n","Epoch [5/5], Step [87/163], Loss: 0.0509, Accuracy: 97.77%\n","Epoch [5/5], Step [88/163], Loss: 0.0510, Accuracy: 97.80%\n","Epoch [5/5], Step [89/163], Loss: 0.0511, Accuracy: 97.82%\n","Epoch [5/5], Step [90/163], Loss: 0.0513, Accuracy: 97.85%\n","Epoch [5/5], Step [91/163], Loss: 0.0520, Accuracy: 97.84%\n","Epoch [5/5], Step [92/163], Loss: 0.0523, Accuracy: 97.86%\n","Epoch [5/5], Step [93/163], Loss: 0.0523, Accuracy: 97.88%\n","Epoch [5/5], Step [94/163], Loss: 0.0528, Accuracy: 97.87%\n","Epoch [5/5], Step [95/163], Loss: 0.0532, Accuracy: 97.89%\n","Epoch [5/5], Step [96/163], Loss: 0.0536, Accuracy: 97.88%\n","Epoch [5/5], Step [97/163], Loss: 0.0539, Accuracy: 97.91%\n","Epoch [5/5], Step [98/163], Loss: 0.0539, Accuracy: 97.93%\n","Epoch [5/5], Step [99/163], Loss: 0.0546, Accuracy: 97.89%\n","Epoch [5/5], Step [100/163], Loss: 0.0547, Accuracy: 97.91%\n","Epoch [5/5], Step [101/163], Loss: 0.0550, Accuracy: 97.90%\n","Epoch [5/5], Step [102/163], Loss: 0.0552, Accuracy: 97.92%\n","Epoch [5/5], Step [103/163], Loss: 0.0558, Accuracy: 97.91%\n","Epoch [5/5], Step [104/163], Loss: 0.0558, Accuracy: 97.93%\n","Epoch [5/5], Step [105/163], Loss: 0.0560, Accuracy: 97.95%\n","Epoch [5/5], Step [106/163], Loss: 0.0563, Accuracy: 97.94%\n","Epoch [5/5], Step [107/163], Loss: 0.0563, Accuracy: 97.96%\n","Epoch [5/5], Step [108/163], Loss: 0.0564, Accuracy: 97.97%\n","Epoch [5/5], Step [109/163], Loss: 0.0564, Accuracy: 97.99%\n","Epoch [5/5], Step [110/163], Loss: 0.0569, Accuracy: 97.98%\n","Epoch [5/5], Step [111/163], Loss: 0.0569, Accuracy: 98.00%\n","Epoch [5/5], Step [112/163], Loss: 0.0572, Accuracy: 98.02%\n","Epoch [5/5], Step [113/163], Loss: 0.0574, Accuracy: 98.04%\n","Epoch [5/5], Step [114/163], Loss: 0.0584, Accuracy: 98.03%\n","Epoch [5/5], Step [115/163], Loss: 0.0609, Accuracy: 97.99%\n","Epoch [5/5], Step [116/163], Loss: 0.0613, Accuracy: 98.01%\n","Epoch [5/5], Step [117/163], Loss: 0.0613, Accuracy: 98.02%\n","Epoch [5/5], Step [118/163], Loss: 0.0620, Accuracy: 97.99%\n","Epoch [5/5], Step [119/163], Loss: 0.0620, Accuracy: 98.00%\n","Epoch [5/5], Step [120/163], Loss: 0.0620, Accuracy: 98.02%\n","Epoch [5/5], Step [121/163], Loss: 0.0621, Accuracy: 98.04%\n","Epoch [5/5], Step [122/163], Loss: 0.0621, Accuracy: 98.05%\n","Epoch [5/5], Step [123/163], Loss: 0.0650, Accuracy: 97.99%\n","Epoch [5/5], Step [124/163], Loss: 0.0656, Accuracy: 97.98%\n","Epoch [5/5], Step [125/163], Loss: 0.0657, Accuracy: 98.00%\n","Epoch [5/5], Step [126/163], Loss: 0.0661, Accuracy: 98.02%\n","Epoch [5/5], Step [127/163], Loss: 0.0664, Accuracy: 98.03%\n","Epoch [5/5], Step [128/163], Loss: 0.0666, Accuracy: 98.05%\n","Epoch [5/5], Step [129/163], Loss: 0.0674, Accuracy: 98.04%\n","Epoch [5/5], Step [130/163], Loss: 0.0676, Accuracy: 98.05%\n","Epoch [5/5], Step [131/163], Loss: 0.0680, Accuracy: 98.07%\n","Epoch [5/5], Step [132/163], Loss: 0.0686, Accuracy: 98.06%\n","Epoch [5/5], Step [133/163], Loss: 0.0692, Accuracy: 98.05%\n","Epoch [5/5], Step [134/163], Loss: 0.0692, Accuracy: 98.06%\n","Epoch [5/5], Step [135/163], Loss: 0.0695, Accuracy: 98.08%\n","Epoch [5/5], Step [136/163], Loss: 0.0698, Accuracy: 98.09%\n","Epoch [5/5], Step [137/163], Loss: 0.0698, Accuracy: 98.11%\n","Epoch [5/5], Step [138/163], Loss: 0.0707, Accuracy: 98.08%\n","Epoch [5/5], Step [139/163], Loss: 0.0714, Accuracy: 98.07%\n","Epoch [5/5], Step [140/163], Loss: 0.0720, Accuracy: 98.06%\n","Epoch [5/5], Step [141/163], Loss: 0.0723, Accuracy: 98.07%\n","Epoch [5/5], Step [142/163], Loss: 0.0726, Accuracy: 98.06%\n","Epoch [5/5], Step [143/163], Loss: 0.0729, Accuracy: 98.08%\n","Epoch [5/5], Step [144/163], Loss: 0.0732, Accuracy: 98.07%\n","Epoch [5/5], Step [145/163], Loss: 0.0746, Accuracy: 98.02%\n","Epoch [5/5], Step [146/163], Loss: 0.0753, Accuracy: 98.01%\n","Epoch [5/5], Step [147/163], Loss: 0.0779, Accuracy: 97.98%\n","Epoch [5/5], Step [148/163], Loss: 0.0782, Accuracy: 97.97%\n","Epoch [5/5], Step [149/163], Loss: 0.0787, Accuracy: 97.97%\n","Epoch [5/5], Step [150/163], Loss: 0.0799, Accuracy: 97.96%\n","Epoch [5/5], Step [151/163], Loss: 0.0837, Accuracy: 97.91%\n","Epoch [5/5], Step [152/163], Loss: 0.0845, Accuracy: 97.90%\n","Epoch [5/5], Step [153/163], Loss: 0.0845, Accuracy: 97.92%\n","Epoch [5/5], Step [154/163], Loss: 0.0863, Accuracy: 97.89%\n","Epoch [5/5], Step [155/163], Loss: 0.0867, Accuracy: 97.88%\n","Epoch [5/5], Step [156/163], Loss: 0.0869, Accuracy: 97.90%\n","Epoch [5/5], Step [157/163], Loss: 0.0876, Accuracy: 97.89%\n","Epoch [5/5], Step [158/163], Loss: 0.0882, Accuracy: 97.88%\n","Epoch [5/5], Step [159/163], Loss: 0.0917, Accuracy: 97.82%\n","Epoch [5/5], Step [160/163], Loss: 0.0918, Accuracy: 97.83%\n","Epoch [5/5], Step [161/163], Loss: 0.0924, Accuracy: 97.83%\n","Epoch [5/5], Step [162/163], Loss: 0.0959, Accuracy: 97.76%\n","Epoch [5/5], Step [163/163], Loss: 0.0962, Accuracy: 97.78%\n","Finished Training\n","Accuracy of the model on the test images: 83.65%\n"]}],"source":["# Train and Evaluate the Model\n","train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=5)\n","accuracy = evaluate_model(model, test_loader)"]},{"cell_type":"code","execution_count":null,"id":"c50102e7","metadata":{"id":"c50102e7"},"outputs":[],"source":["# save model to Google Drive\n","model_save_name = 'pneumonia_resnet18.pt'\n","path = F\"/content/drive/MyDrive/AI Engineer Bootcamp/Project/Final Project/4. Pneumonia Prediction/{model_save_name}\"\n","torch.save(model.state_dict(), path)"]},{"cell_type":"code","execution_count":null,"id":"Danol99H6Uw2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1728554334380,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"Danol99H6Uw2","outputId":"8e8163d5-a90a-4110-a357-4de97718c5c8"},"outputs":[{"data":{"text/plain":["83.65384615384616"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["accuracy"]},{"cell_type":"code","execution_count":null,"id":"c9120366-86dc-4314-ba9d-66f60ae5a884","metadata":{"id":"c9120366-86dc-4314-ba9d-66f60ae5a884"},"outputs":[],"source":["#Write your code for inference here\n","# Define class names (label for the 15 types of flowers)\n","class_names = ['NORMAL', 'PNEUMONIA']\n","\n","# Function to make prediction using Gradio\n","def predict(image):\n","    # Preprocess image\n","    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and send to GPU if available\n","\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted = torch.max(output, 1)\n","        label = class_names[predicted.item()]\n","\n","    return label\n","\n","# Gradio Interface\n","interface = gr.Interface(\n","    fn=predict,  # Prediction function\n","    inputs=gr.Image(type=\"pil\"),  # Input type is an image (uploaded by user)\n","    outputs=\"text\",  # Output is the predicted label (flower type)\n","    title=\"Pneumia Xray\",\n","    description=\"Upload an image of x-ray, and the model will predict the person have pneumonia or not.\"\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"bJCiM1gn6nlY","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"executionInfo":{"elapsed":1425,"status":"ok","timestamp":1728554356387,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"bJCiM1gn6nlY","outputId":"60be1123-2f9f-4449-908f-7613764a38f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://fd40d2d4b1a085fafe.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://fd40d2d4b1a085fafe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["interface.launch()"]},{"cell_type":"code","execution_count":null,"id":"ca04df60-d131-4108-88ae-18c253cfa1ba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308274,"status":"ok","timestamp":1728554733367,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"ca04df60-d131-4108-88ae-18c253cfa1ba","outputId":"1ec91895-ec6c-4de3-f19f-4b2b93fd915e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","^C\n"]}],"source":["#Write your code for publishing here\n","!huggingface-cli login\n"]},{"cell_type":"code","execution_count":null,"id":"KKJvmOg15FyW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3144,"status":"ok","timestamp":1728554769135,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"KKJvmOg15FyW","outputId":"5e89f42c-7136-45fd-b543-b1e3ef0ab4c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"]}],"source":["!pip install huggingface_hub\n","from huggingface_hub import login"]},{"cell_type":"code","execution_count":null,"id":"0QnSxeTd5OD7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1728554808448,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"0QnSxeTd5OD7","outputId":"743aaeac-e353-4349-a3bc-a803b65aa78d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["login(token=\"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\")"]},{"cell_type":"code","execution_count":null,"id":"15fcc782","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["2c5b47f87590432da718234230b26ef9","dd0dde5cae4b44389299ea075a4ef6bd","724d9f6f7e494640a1e996a50416db3e","69335c65f7b148f7a2612a0e16e00e65","0c27c39683164074a619e150deefe73c","a9e41fa189994a44825252c1b370c5a8","2c46e7fe78174b67bc287a49879ab760","1841747b6d2449258611cb199dd7ef85","b516c24116a649a3aa129428451c9a8d","6f1e728a69324300be046458eef3f699","17897a4e7929401d89441bb994db8346"]},"executionInfo":{"elapsed":4744,"status":"ok","timestamp":1728555452724,"user":{"displayName":"Fathur Imam Mujaddid","userId":"00438109393749372913"},"user_tz":-420},"id":"15fcc782","outputId":"aeb61bed-a206-487f-a02e-458ccdba3e87"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c5b47f87590432da718234230b26ef9","version_major":2,"version_minor":0},"text/plain":["pneumonia_resnet18.pt:   0%|          | 0.00/44.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["CommitInfo(commit_url='https://huggingface.co/fathurim/pneumonia_resnet/commit/bd58680cbc26d04a6e7ecbab94b3098700d1ea29', commit_message='Upload pneumonia_resnet18.pt with huggingface_hub', commit_description='', oid='bd58680cbc26d04a6e7ecbab94b3098700d1ea29', pr_url=None, repo_url=RepoUrl('https://huggingface.co/fathurim/pneumonia_resnet', endpoint='https://huggingface.co', repo_type='model', repo_id='fathurim/pneumonia_resnet'), pr_revision=None, pr_num=None)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["from huggingface_hub import HfApi\n","api = HfApi()\n","api.upload_file(\n","    path_or_fileobj=\"/content/drive/MyDrive/AI Engineer Bootcamp/Project/Final Project/4. Pneumonia Prediction/pneumonia_resnet18.pt\",\n","    path_in_repo=\"pneumonia_resnet18.pt\",\n","    repo_id=\"fathurim/pneumonia_resnet\",\n","    repo_type=\"model\",\n",")"]},{"cell_type":"markdown","id":"aea843c0-2811-416f-af2d-a4e46a65a11a","metadata":{"id":"aea843c0-2811-416f-af2d-a4e46a65a11a"},"source":["FIN"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Of79jjV-RO_l7SkN00F2RSFEg_oIcOf4","timestamp":1728533558444},{"file_id":"1x_JwfHr0uYbUtXSQKRzYxGS1mmzHcZu3","timestamp":1727025838764}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0c27c39683164074a619e150deefe73c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17897a4e7929401d89441bb994db8346":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1841747b6d2449258611cb199dd7ef85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c46e7fe78174b67bc287a49879ab760":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c5b47f87590432da718234230b26ef9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd0dde5cae4b44389299ea075a4ef6bd","IPY_MODEL_724d9f6f7e494640a1e996a50416db3e","IPY_MODEL_69335c65f7b148f7a2612a0e16e00e65"],"layout":"IPY_MODEL_0c27c39683164074a619e150deefe73c"}},"69335c65f7b148f7a2612a0e16e00e65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f1e728a69324300be046458eef3f699","placeholder":"​","style":"IPY_MODEL_17897a4e7929401d89441bb994db8346","value":" 44.8M/44.8M [00:03&lt;00:00, 13.3MB/s]"}},"6f1e728a69324300be046458eef3f699":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"724d9f6f7e494640a1e996a50416db3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1841747b6d2449258611cb199dd7ef85","max":44790376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b516c24116a649a3aa129428451c9a8d","value":44790376}},"a9e41fa189994a44825252c1b370c5a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b516c24116a649a3aa129428451c9a8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd0dde5cae4b44389299ea075a4ef6bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9e41fa189994a44825252c1b370c5a8","placeholder":"​","style":"IPY_MODEL_2c46e7fe78174b67bc287a49879ab760","value":"pneumonia_resnet18.pt: 100%"}}}}},"nbformat":4,"nbformat_minor":5}